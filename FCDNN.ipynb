{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:03:04.470534Z",
     "iopub.status.busy": "2023-05-31T19:03:04.470104Z",
     "iopub.status.idle": "2023-05-31T19:03:05.029980Z",
     "shell.execute_reply": "2023-05-31T19:03:05.029080Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.rc(\"text\", usetex=True)\n",
    "plt.rc(\"font\", family=\"cm\")\n",
    "plt.rcParams[\"grid.color\"] = (0.5, 0.5, 0.5, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:03:05.034155Z",
     "iopub.status.busy": "2023-05-31T19:03:05.033326Z",
     "iopub.status.idle": "2023-05-31T19:04:55.592374Z",
     "shell.execute_reply": "2023-05-31T19:04:55.591774Z"
    }
   },
   "outputs": [],
   "source": [
    "X_dataframe = pd.read_csv(\"/mnt/ferracci/features_dataframe_new.csv.gz\")\n",
    "X = np.load(\"/mnt/ferracci/features_new.npz\", allow_pickle=True)['a']\n",
    "y = np.array(pd.read_csv(\"/mnt/ferracci/targets_dataframe_new.csv.gz\")[\"Qedep\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:04:55.595848Z",
     "iopub.status.busy": "2023-05-31T19:04:55.595494Z",
     "iopub.status.idle": "2023-05-31T19:04:55.935636Z",
     "shell.execute_reply": "2023-05-31T19:04:55.935133Z"
    }
   },
   "outputs": [],
   "source": [
    "# we are only interested in the selected features\n",
    "with open('/home/ferracci/new_dataset/features_list.txt', 'r') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "features_list = file_content.split('\\n')\n",
    "selected_features_names = eval(features_list[0])\n",
    "\n",
    "selected_X_dataframe = X_dataframe[selected_features_names]\n",
    "X = X[:, [X_dataframe.columns.get_loc(name) for name in selected_features_names]]\n",
    "selected_X_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:04:55.968083Z",
     "iopub.status.busy": "2023-05-31T19:04:55.967679Z",
     "iopub.status.idle": "2023-05-31T19:05:00.112097Z",
     "shell.execute_reply": "2023-05-31T19:05:00.111444Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import optuna\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchmetrics import MeanSquaredError\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "mean_squared_error = MeanSquaredError().to(device)\n",
    "\n",
    "# normalize dataset \n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "X_train_std = np.std(X_train, axis=0)\n",
    "X_train_norm = (X_train - X_train_mean) / X_train_std\n",
    "X_valid_norm = (X_valid - X_train_mean) / X_train_std \n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train_norm), torch.Tensor(y_train))\n",
    "valid_dataset = TensorDataset(torch.Tensor(X_valid_norm), torch.Tensor(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.115460Z",
     "iopub.status.busy": "2023-05-31T19:05:00.114909Z",
     "iopub.status.idle": "2023-05-31T19:05:00.118407Z",
     "shell.execute_reply": "2023-05-31T19:05:00.117924Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=1024\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.120805Z",
     "iopub.status.busy": "2023-05-31T19:05:00.120410Z",
     "iopub.status.idle": "2023-05-31T19:05:00.124926Z",
     "shell.execute_reply": "2023-05-31T19:05:00.124457Z"
    }
   },
   "outputs": [],
   "source": [
    "class FCDNN(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden_layers, n_hidden_units, activation_name):\n",
    "        super().__init__()\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.activation_name = activation_name\n",
    "\n",
    "        # first hidden layer \n",
    "        self.dense_first = nn.Linear(n_features, n_hidden_units)\n",
    "\n",
    "        # prototype of intermediate hidden layer\n",
    "        self.dense = nn.Linear(n_hidden_units, n_hidden_units)\n",
    "\n",
    "        # last hidden layer \n",
    "        self.dense_last = nn.Linear(n_hidden_units, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = get_activation_layer(self.activation_name, self.dense_first(x))\n",
    "\n",
    "        for i in range(self.n_hidden_layers-1):\n",
    "            x = get_activation_layer(self.activation_name, self.dense(x))\n",
    "\n",
    "        x = self.dense_last(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.127358Z",
     "iopub.status.busy": "2023-05-31T19:05:00.126927Z",
     "iopub.status.idle": "2023-05-31T19:05:00.131034Z",
     "shell.execute_reply": "2023-05-31T19:05:00.130552Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn, \n",
    "               optimizer: torch.optim.Optimizer, device=device):\n",
    "    train_loss, train_mse = 0, 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X).squeeze()\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_mse += mean_squared_error(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_mse /= len(dataloader)\n",
    "    return train_loss, train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.133457Z",
     "iopub.status.busy": "2023-05-31T19:05:00.133052Z",
     "iopub.status.idle": "2023-05-31T19:05:00.136867Z",
     "shell.execute_reply": "2023-05-31T19:05:00.136404Z"
    }
   },
   "outputs": [],
   "source": [
    "def valid_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn, device=device):\n",
    "    valid_loss, valid_mse = 0, 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for (X, y) in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X).squeeze()\n",
    "            valid_loss += loss_fn(y_pred, y)\n",
    "            valid_mse += mean_squared_error(y_pred, y)\n",
    "        valid_loss /= len(dataloader)\n",
    "        valid_mse /= len(dataloader)\n",
    "\n",
    "    return valid_loss, valid_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.139109Z",
     "iopub.status.busy": "2023-05-31T19:05:00.138735Z",
     "iopub.status.idle": "2023-05-31T19:05:00.141744Z",
     "shell.execute_reply": "2023-05-31T19:05:00.141275Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_activation_layer(activation_name, x):\n",
    "    if activation_name == \"SELU\":\n",
    "        activation_layer = F.selu(x)\n",
    "    elif activation_name == \"ELU\":\n",
    "        activation_layer = F.elu(x)\n",
    "    else:\n",
    "        activation_layer = F.relu(x)\n",
    "    \n",
    "    return activation_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.144086Z",
     "iopub.status.busy": "2023-05-31T19:05:00.143691Z",
     "iopub.status.idle": "2023-05-31T19:05:00.147333Z",
     "shell.execute_reply": "2023-05-31T19:05:00.146872Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer(trial, model):\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\"])\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "  \n",
    "    if optimizer_name == \"Adam\": \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    else:\n",
    "        optimizer = torch.optim.RMSprop(model.parameters())\n",
    "  \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.150327Z",
     "iopub.status.busy": "2023-05-31T19:05:00.149906Z",
     "iopub.status.idle": "2023-05-31T19:05:00.153955Z",
     "shell.execute_reply": "2023-05-31T19:05:00.153447Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_scheduler(trial, optimizer):\n",
    "    scheduler_name = trial.suggest_categorical(\"scheduler\", [\"None\", \"Exp\", \"Cos\"])\n",
    "\n",
    "    if scheduler_name == \"Exp\":\n",
    "        gamma = trial.suggest_float(\"gamma\", 0.1, 0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma)\n",
    "    elif scheduler_name == \"Cos\":\n",
    "        T_max = trial.suggest_int(\"T_max\", 10, 1000)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.156742Z",
     "iopub.status.busy": "2023-05-31T19:05:00.156159Z",
     "iopub.status.idle": "2023-05-31T19:05:00.159371Z",
     "shell.execute_reply": "2023-05-31T19:05:00.158852Z"
    }
   },
   "outputs": [],
   "source": [
    "def MAPELoss(output, target, epsilon=1e-7):\n",
    "    error = torch.abs((target - output) / (target + epsilon))\n",
    "    loss = torch.mean(error)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.162030Z",
     "iopub.status.busy": "2023-05-31T19:05:00.161584Z",
     "iopub.status.idle": "2023-05-31T19:05:00.167778Z",
     "shell.execute_reply": "2023-05-31T19:05:00.167306Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(best_epoch, train_losses, valid_losses, train_mses, valid_mses):\n",
    "    fig, ax_left = plt.subplots(nrows=1, ncols=1, figsize=(7,5), dpi=150)\n",
    "\n",
    "    ax_left.plot(range(best_epoch+1), np.array(train_losses[:best_epoch+1])*100, color=\"blue\", label=\"Training MAPE\")\n",
    "    ax_left.plot(range(best_epoch+1), np.array(valid_losses[:best_epoch+1])*100, color=\"red\", label=\"Validation MAPE\")\n",
    "    ax_left.set_ylim((0.0, 4))\n",
    "    ax_left.set_ylabel(\"MAPE, $\\%$ curves\", fontsize=15)\n",
    "    ax_left.set_xlabel(\"Number of epochs\", fontsize=15)\n",
    "    ax_left.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "    ax_left.tick_params(axis=\"both\", which='minor', labelsize=12)\n",
    "\n",
    "    ax_right = ax_left.twinx()\n",
    "    ax_right.plot(range(best_epoch+1), train_mses[:best_epoch+1], color=\"orange\", label=\"Training MSE\")\n",
    "    ax_right.plot(range(best_epoch+1), valid_mses[:best_epoch+1], color=\"purple\", label=\"Validation MSE\")\n",
    "    ax_right.set_ylim((0.0, 0.04))\n",
    "    ax_right.set_ylabel(\"MSE curves\", fontsize=15, rotation=270, labelpad=20)\n",
    "    ax_right.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "    ax_right.tick_params(axis=\"both\", which='minor', labelsize=12)\n",
    "\n",
    "    lines1, labels1 = ax_left.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax_right.get_legend_handles_labels()\n",
    "    ax_left.legend(lines1 + lines2, labels1 + labels2, loc=0, fontsize=12, fancybox=False, edgecolor=\"k\")\n",
    "    ax_left.grid()\n",
    "\n",
    "    fig.savefig(\"/home/ferracci/new_dataset/images/FCDNN_learning_curve.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.2)\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.170139Z",
     "iopub.status.busy": "2023-05-31T19:05:00.169724Z",
     "iopub.status.idle": "2023-05-31T19:05:00.175878Z",
     "shell.execute_reply": "2023-05-31T19:05:00.175402Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_hidden_layers = trial.suggest_int(\"hidden_layers\", 6, 24)\n",
    "    n_hidden_units = trial.suggest_int(\"hidden_units\", 1, 256) \n",
    "    activation_name = trial.suggest_categorical(\"activation\", [\"ReLU\", \"SELU\", \"ELU\"]) \n",
    "\n",
    "    global model\n",
    "    model = FCDNN(13, n_hidden_layers, n_hidden_units, activation_name).to(device)\n",
    "    optimizer = get_optimizer(trial, model)\n",
    "    scheduler = get_scheduler(trial, optimizer)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    global best_epoch\n",
    "    best_epoch = 0\n",
    "    patience = 50\n",
    "    epochs_no_improvement = 0\n",
    "    epochs = 200\n",
    "    global train_losses, train_mses, valid_losses, valid_mses\n",
    "    train_losses, train_mses, valid_losses, valid_mses = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_mse = train_step(model=model, dataloader=train_dataloader, loss_fn=MAPELoss, \n",
    "                                           optimizer=optimizer, device=device)\n",
    "        valid_loss, valid_mse = valid_step(model=model, dataloader=valid_dataloader, loss_fn=MAPELoss, device=device)\n",
    "\n",
    "        # handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            print(f\"Trial #{trial.number}. PRUNED\")\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # manually implement early stopping\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improvement = 0\n",
    "            torch.save(model.state_dict(), f\"/mnt/ferracci/fcdnn_tuned_{trial.number}.pth\")\n",
    "        else:\n",
    "            epochs_no_improvement += 1\n",
    "        if epochs_no_improvement == patience:\n",
    "            break\n",
    "\n",
    "        trial.report(best_loss, epoch)\n",
    "        train_losses.append(train_loss.item())\n",
    "        train_mses.append(train_mse.item())\n",
    "        valid_losses.append(valid_loss.item())\n",
    "        valid_mses.append(valid_mse.item())\n",
    "\n",
    "    print(f\"Trial #{trial.number}. Best MAPE: {best_loss:.5f}.\")\n",
    "    \n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:00.178168Z",
     "iopub.status.busy": "2023-05-31T19:05:00.177768Z",
     "iopub.status.idle": "2023-06-01T14:16:44.087145Z",
     "shell.execute_reply": "2023-06-01T14:16:44.086483Z"
    }
   },
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def callback(study, trial):\n",
    "    if study.best_trial == trial:\n",
    "        plot_learning_curves(best_epoch, train_losses, valid_losses, train_mses, valid_mses)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=200, callbacks=[callback])\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"\\nBest MAPE: {trial.value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T14:16:44.090527Z",
     "iopub.status.busy": "2023-06-01T14:16:44.090237Z",
     "iopub.status.idle": "2023-06-01T14:16:44.152372Z",
     "shell.execute_reply": "2023-06-01T14:16:44.151812Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dataframe = study.trials_dataframe()\n",
    "results_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T14:16:44.155429Z",
     "iopub.status.busy": "2023-06-01T14:16:44.154942Z",
     "iopub.status.idle": "2023-06-01T14:16:44.168189Z",
     "shell.execute_reply": "2023-06-01T14:16:44.167689Z"
    }
   },
   "outputs": [],
   "source": [
    "trials = results_dataframe[(results_dataframe[\"state\"] == \"COMPLETE\") & (results_dataframe[\"value\"] < 0.015)]\n",
    "trials = trials.drop([\"number\", \"datetime_start\", \"datetime_complete\", \"duration\", \"state\", \"params_T_max\", \"params_gamma\"], axis=1)\n",
    "\n",
    "# swap columns so that mse is the last column\n",
    "columns = list(trials.columns)\n",
    "trials[columns[0]] = 100*trials[columns[0]]\n",
    "columns = [columns[2], columns[3], columns[1], columns[5], columns[4], columns[6]] + [columns[0]]\n",
    "trials = trials[columns]\n",
    "labels = [\"number of\\nlayers\", \"number of\\nunits\", \"activation function\", \"optimizer\", \"learning rate\", \"learning scheduler\", \"MAPE, \\%\"]\n",
    "trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T14:16:44.170695Z",
     "iopub.status.busy": "2023-06-01T14:16:44.170244Z",
     "iopub.status.idle": "2023-06-01T14:16:46.511655Z",
     "shell.execute_reply": "2023-06-01T14:16:46.511076Z"
    }
   },
   "outputs": [],
   "source": [
    "from helper_functions.parallel_coordinates_plot import * \n",
    "\n",
    "fig = plot_parallel_coordinates(trials, labels, linewidth=0.8, alpha=0.8)\n",
    "fig.set_dpi(150)\n",
    "fig.supylabel(\"Hyperparameter tuning\", fontsize=15, x=0.05)\n",
    "fig.savefig(\"/home/ferracci/new_dataset/images/FCDNN_hyperparameter_tuning.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T14:16:46.515930Z",
     "iopub.status.busy": "2023-06-01T14:16:46.515504Z",
     "iopub.status.idle": "2023-06-01T14:16:46.519118Z",
     "shell.execute_reply": "2023-06-01T14:16:46.518597Z"
    }
   },
   "outputs": [],
   "source": [
    "params = study.best_params\n",
    "\n",
    "# save dictionary to a file\n",
    "with open(\"/home/ferracci/new_dataset/fcdnn_study.pkl\", \"wb\") as file:\n",
    "    pickle.dump(params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T14:16:46.521505Z",
     "iopub.status.busy": "2023-06-01T14:16:46.521069Z",
     "iopub.status.idle": "2023-06-01T14:16:46.525192Z",
     "shell.execute_reply": "2023-06-01T14:16:46.524731Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dictionary from file\n",
    "with open(\"/home/ferracci/new_dataset/fcdnn_study.pkl\", \"rb\") as file:\n",
    "    params = pickle.load(file)\n",
    "\n",
    "params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T14:16:46.545455Z",
     "iopub.status.busy": "2023-06-01T14:16:46.545017Z",
     "iopub.status.idle": "2023-06-01T14:16:46.548116Z",
     "shell.execute_reply": "2023-06-01T14:16:46.547631Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from helper_functions.model_evaluation import plot_gaussian_fit\n",
    "from helper_functions.model_evaluation import energy_res_fit\n",
    "from helper_functions.model_evaluation import get_a_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T14:16:46.550357Z",
     "iopub.status.busy": "2023-06-01T14:16:46.549993Z",
     "iopub.status.idle": "2023-06-01T14:16:51.620153Z",
     "shell.execute_reply": "2023-06-01T14:16:51.619530Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_files = list(Path(\"/mnt/ferracci/\").glob(\"features_test_*\"))\n",
    "y_test_files = list(Path(\"/mnt/ferracci/\").glob(\"targets_dataframe_test_*\"))\n",
    "X_test, y_test = [], []\n",
    "\n",
    "for X_test_file in X_test_files:\n",
    "    X_test.append(np.load(X_test_file)[\"a\"][:, [X_dataframe.columns.get_loc(name) for name in selected_features_names]])\n",
    "for y_test_file in y_test_files:\n",
    "    y_test.append(np.array(pd.read_csv(y_test_file)[\"Qedep\"]))\n",
    "\n",
    "energies = [0, 1, 10, 7, 6, 2, 0.1, 9, 5, 3, 8, 4, 0.3, 0.6]\n",
    "X_test = [x for _, x in sorted(zip(energies, X_test))]\n",
    "y_test = [x for _, x in sorted(zip(energies, y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T14:16:51.623354Z",
     "iopub.status.busy": "2023-06-01T14:16:51.622838Z",
     "iopub.status.idle": "2023-06-01T14:16:51.630344Z",
     "shell.execute_reply": "2023-06-01T14:16:51.629867Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dictionary from file\n",
    "with open(\"/home/ferracci/new_dataset/fcdnn_study.pkl\", \"rb\") as file:\n",
    "    params = pickle.load(file)\n",
    "    \n",
    "# load the saved model from file\n",
    "best_model = FCDNN(13, params[\"hidden_layers\"], params[\"hidden_units\"], params[\"activation\"])\n",
    "best_model.load_state_dict(torch.load(f\"/mnt/ferracci/fcdnn_tuned_{trial.number}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T14:16:51.632862Z",
     "iopub.status.busy": "2023-06-01T14:16:51.632460Z",
     "iopub.status.idle": "2023-06-01T14:17:04.266230Z",
     "shell.execute_reply": "2023-06-01T14:17:04.265758Z"
    }
   },
   "outputs": [],
   "source": [
    "bias, res = [], []\n",
    "err_bias, err_res = [], []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    best_model.eval()\n",
    "    with torch.inference_mode():\n",
    "        X_test[i] = (X_test[i] - X_train_mean) / X_train_std\n",
    "        X_test[i], y_test[i] = torch.Tensor(X_test[i]).float(), torch.Tensor(y_test[i])\n",
    "        y_pred = best_model(X_test[i]).squeeze()\n",
    "        err = (y_test[i] - y_pred).numpy()\n",
    "        err = err[err - np.mean(err) < 5*np.std(err)]\n",
    "\n",
    "    mean, std, err_mean, err_std = plot_gaussian_fit(data=err, n_bins=100, name=\"fcdnn\", index=i)\n",
    "    bias.append(100 * mean / np.mean(y_test[i].numpy()))\n",
    "    res.append(100 * std / np.mean(y_test[i].numpy()))\n",
    "    err_bias.append(100 * err_mean / np.mean(y_test[i].numpy()))\n",
    "    err_res.append(100 * err_std / np.mean(y_test[i].numpy()))\n",
    "\n",
    "# get fit parameters\n",
    "a, b, c, pcov = energy_res_fit([np.mean(y_test[i].numpy()) for i in range(1, len(y_test)-1)], res[1:-1], err_res[1:-1])\n",
    "err_a, err_b, err_c = np.sqrt(np.abs(np.diag(pcov)[0])), np.sqrt(np.abs(np.diag(pcov)[1])), np.sqrt(np.abs(np.diag(pcov)[2]))\n",
    "cov_ab, cov_ac, cov_bc = pcov[0, 1], pcov[0, 2], pcov[1, 2]\n",
    "\n",
    "print(f\"a = {a:.3f} +/- {err_a:.3f}\")\n",
    "print(f\"b = {b:.3f} +/- {err_b:.3f}\")\n",
    "print(f\"c = {c:.3f} +/- {err_c:.3f}\")\n",
    "\n",
    "a_tilde, err_a_tilde = get_a_tilde(a, b, c, err_a, err_b, err_c, cov_ab, cov_ac, cov_bc)\n",
    "print(f\"\\nã = {a_tilde:.3f} +/- {err_a_tilde:.3f}\")\n",
    "\n",
    "with open('/home/ferracci/new_dataset/fcdnn_results.txt', 'w') as f:\n",
    "    f.write(str(bias))\n",
    "    f.write('\\n')\n",
    "    f.write(str(res))\n",
    "    f.write('\\n')\n",
    "    f.write(str(err_bias))\n",
    "    f.write('\\n')\n",
    "    f.write(str(err_res))\n",
    "    f.write('\\n')\n",
    "    f.write(str([a, b, c, err_a, err_b, err_c, a_tilde, err_a_tilde]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
